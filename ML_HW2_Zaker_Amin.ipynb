{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e545c6c4",
   "metadata": {},
   "source": [
    "Assignment: Binary Classification with Logistic Regression\n",
    "\n",
    "In this assignment, you will work with the Iris dataset to perform binary classification using logistic regression. The Iris dataset contains samples from three different species of iris flowers, but for this assignment, you will focus on classifying Iris Setosa (class 0) versus the combination of the other two classes (class 1).\n",
    "\n",
    "Here are the steps you need to follow for this assignment:\n",
    "\n",
    "Step 1: Load the Iris dataset\n",
    "\n",
    "Load the Iris dataset using sklearn.datasets.load_iris().\n",
    "Extract the feature matrix X and the target vector y.\n",
    "\n",
    "\n",
    "Step 2: Preprocess the data\n",
    "\n",
    "To convert this problem into binary classification, create a new target vector y_binary where Iris Setosa (class 0) is labeled as 1, and the other two classes are labeled as 0.\n",
    "\n",
    "\n",
    "Step 3: Split the dataset\n",
    "\n",
    "Split the dataset into training and testing sets using train_test_split() from sklearn.model_selection.\n",
    "Use 80% of the data for training and 20% for testing. Set the random_state to ensure reproducibility.\n",
    "\n",
    "Step 4: Define the cost function (logistic loss)\n",
    "\n",
    "Implement the logistic loss function, which calculates the cost of your model's predictions.\n",
    "\n",
    "Step 5: Define the training function\n",
    "\n",
    "Implement a training function that uses gradient descent to optimize the logistic regression model.\n",
    "The function should take input data, learning rate, number of iterations, and regularization parameter as arguments.\n",
    "\n",
    "Step 6: Train the model\n",
    "\n",
    "Use the training function to train your logistic regression model on the training data.\n",
    "Obtain the weight vector W and bias term b.\n",
    "\n",
    "\n",
    "Step 7: Define the prediction function\n",
    "\n",
    "Implement a prediction function that takes input data and the trained model's weights and bias.\n",
    "The prediction function should use the logistic sigmoid function to make binary predictions (0 or 1).\n",
    "\n",
    "\n",
    "Step 8: Predict on the test set\n",
    "\n",
    "Use the prediction function to predict the classes for the test set X_test using the obtained weights and bias.\n",
    "\n",
    "\n",
    "Step 9: Evaluate the model's performance\n",
    "\n",
    "Calculate the accuracy of your model using accuracy_score() from sklearn.metrics.\n",
    "Generate the confusion matrix using confusion_matrix() from sklearn.metrics.\n",
    "Generate the classification report using classification_report() from sklearn.metrics.\n",
    "Print out the accuracy, confusion matrix, and classification report to evaluate your model's performance.\n",
    "Make sure to comment your code and provide explanations for each step. This assignment will help you understand the basics of binary classification, logistic regression, and how to evaluate the performance of your model using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f956686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[20  0]\n",
      " [ 0 10]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Step 2: Preprocess the data for binary classification\n",
    "# Create a binary target vector where Iris Setosa (class 0) is labeled as 1, and others as 0\n",
    "y_binary = (y == 0).astype(int)\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Define the logistic loss (cost) function\n",
    "def logistic_loss(y_true, y_pred):\n",
    "    epsilon = 1e-15  # Small value to prevent log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip predictions to avoid log(0)\n",
    "    loss = - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return np.mean(loss)\n",
    "\n",
    "# Step 5: Define the training function using gradient descent\n",
    "def train_logistic_regression(X, y, learning_rate, num_iterations, reg_param):\n",
    "    m, n = X.shape  # Number of samples and features\n",
    "    w = np.zeros(n)  # Initialize weights to zeros\n",
    "    b = 0  # Initialize bias to zero\n",
    "    \n",
    "    # Gradient descent\n",
    "    for iteration in range(num_iterations):\n",
    "        z = np.dot(X, w) + b\n",
    "        y_pred = 1 / (1 + np.exp(-z))\n",
    "        \n",
    "        # Calculate gradients\n",
    "        dw = (1 / m) * np.dot(X.T, (y_pred - y)) + (reg_param / m) * w\n",
    "        db = (1 / m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Update weights and bias\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "# Step 6: Train the logistic regression model\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "reg_param = 0.1\n",
    "\n",
    "W, b = train_logistic_regression(X_train, y_train, learning_rate, num_iterations, reg_param)\n",
    "\n",
    "# Step 7: Define the prediction function\n",
    "def predict(X, W, b):\n",
    "    z = np.dot(X, W) + b\n",
    "    y_pred = 1 / (1 + np.exp(-z))\n",
    "    return (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# Step 8: Predict on the test set\n",
    "y_pred_test = predict(X_test, W, b)\n",
    "\n",
    "# Step 9: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "confusion = confusion_matrix(y_test, y_pred_test)\n",
    "classification_rep = classification_report(y_test, y_pred_test)\n",
    "\n",
    "# Print out the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d500c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
